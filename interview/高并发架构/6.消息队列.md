### 1. 为什么使用消息队列？消息队列有哪些优点和缺点？kafka、activemq、rabbitmq、rocketmq都有哪些场景，技术选型？

为什么使用消息队列，主要讲用了消息队列的那些使用场景；

优点：解耦、异步、削峰

缺点：系统可用性降低，一旦mq故障了，系统A就会没法发送消息，导致整个系统崩溃；

​			系统复杂度升高；

​			因为异步调用的延时大于RPC同步调用是，所以会出现短暂的不一致性；

​			无法做到事务的强一致，需要分布式事务方案来处理；

​			服务的消费方要做幂等设计，来规避重复调用的问题；



消息队列技术选型：

| 特性                    | ActiveMQ                                                     | RabbitMQ                                                     | RocketMQ                                                     | Kafka                                                        |
| :---------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| 单机吞吐量              | 万级，吞吐量比RocketMQ和Kafka低了一个数量级                  | 万级，吞吐量比RocketMQ和Kafka低了一个数量级                  | 10W级，RocketMQ也是支持高吞吐的MQ                            | 10W级，RocketMQ也是支持高吞吐的MQ，一般配合大数据做实时计算和日志采集场景 |
| topic数量对吞吐量的影响 |                                                              |                                                              | topic可以达到几百几千个的级别，吞吐量会有较小幅度的下降，已支撑大量的topic | topic从十几个到几百个的时候，吞吐量会大幅度下降，支撑大规模topic需要增加更多的机器资源 |
| 时效性                  | ms级                                                         | 微秒级，低延时                                               | ms级                                                         |                                                              |
| 可用性                  | 高，基于主从架构实现高可用                                   | 高，基于主从架构实现高可用                                   | 非常高，分布式架构                                           | 非常高，kafka是分布式的，一个数据多个副本，少量机器宕机，不会丢失数据，不会导致不可用 |
| 消息可靠性              | 有较低的概率丢失数据                                         |                                                              | 经过参数优化配置，可以做到0丢失                              | 经过参数优化配置，可以做到0丢失                              |
| 功能特性                | MQ领域的功能及其完备                                         | 基于erlang开发，所以并发能力强，性能极好，延时很低           | MQ功能较为完善，还是分布式的，扩展性好                       | 功能较为简单，主要支持简单的MQ功能，在大数据梁宇的实时计算以及日志采集被大规模使用，是事实上的标准 |
| 优劣势总结              | 1.成熟功能强大 ；               2.偶尔丢消息     3.社区不活跃 | 1. 性能高，延时低             2.社区活跃；3.管理后台比较好；   4.维护语言不是很好； | 1.单机吞吐量10w；2.分布式架构；3.社区活跃度高；              | 1.在topic很多的情况吞吐量不是很高；2.扩展性强；              |







### 2.引入消息队列之后该如何保证其高可用？

#### 2.1 RabbitMQ：

普通集群模式(无高可用性)：

> 普通集群模式，意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你**创建的 queue，只会放在一个 RabbitMQ 实例上**，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。			<img src="https://raw.githubusercontent.com/shishan100/Java-Interview-Advanced/master/images/mq-7.png"/>
>
> 这种方式确实很麻烦，也不怎么好，**没做到所谓的分布式**，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据，前者有**数据拉取的开销**，后者导致**单实例性能瓶颈**。
>
> 而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你**开启了消息持久化**，让 RabbitMQ 落地存储消息的话，**消息不一定会丢**，得等这个实例恢复了，然后才可以继续从这个 queue 拉取数据。
>
> 所以这个事儿就比较尴尬了，这就**没有什么所谓的高可用性**，**这方案主要是提高吞吐量的**，就是说让集群中多个节点来服务某个 queue 的读写操作。



#### 镜像集群模式(高可用)

> 这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会**存在于多个实例上**，就是说，每个 RabbitMQ 节点都有这个 queue 的一个**完整镜像**，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把**消息同步**到多个实例的 queue 上。
>
> <img src="https://raw.githubusercontent.com/shishan100/Java-Interview-Advanced/master/images/mq-8.png"/>
>
> 那么**如何开启这个镜像集群模式**呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是**镜像集群模式的策略**，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。
>
> 这样的话，好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！第二，这么玩儿，不是分布式的，就**没有扩展性可言**了，如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并**没有办法线性扩展**你的 queue。你想，如果这个 queue 的数据量很大，大到这个机器上的容量无法容纳了，此时该怎么办呢？

### 2.2 Kafka的高可用

> Kafka 一个最基本的架构认识：由多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。
>
> 这就是**天然的分布式消息队列**，就是说一个 topic 的数据，是**分散放在多个机器上的，每个机器就放一部分数据**。
>
> <img src="https://raw.githubusercontent.com/shishan100/Java-Interview-Advanced/master/images/kafka-after.png"/>
>
> 这么搞，就有所谓的**高可用性**了，因为如果某个 broker 宕机了，没事儿，那个 broker上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中**重新选举**一个新的 leader 出来，大家继续读写那个新的 leader 即可。这就有所谓的高可用性了。
>
> **写数据**的时候，生产者就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据了，就会发送 ack 给 leader，leader 收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）
>
> **消费**的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都同步成功返回 ack 的时候，这个消息才会被消费者读到。
>
> 看到这里，相信你大致明白了 Kafka 是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要是遇上面试官确实是 Kafka 高手，深挖了问，那你只能说不好意思，太深入的你没研究过。

#### 2.3 RocketMQ高可用架构

> <img src="https://github.com/apache/rocketmq/blob/master/docs/cn/image/rocketmq_architecture_1.png?raw=true"/>
>
> RocketMQ架构上主要分为四部分，如上图所示:
>
> 
>
> - **Producer**：消息发布的角色，支持分布式集群方式部署。Producer通过MQ的负载均衡模块选择相应的Broker集群队列进行消息投递，投递的过程支持快速失败并且低延迟。
>
> 
>
> - **Consumer**：消息消费的角色，支持分布式集群方式部署。支持以push推，pull拉两种模式对消息进行消费。同时也支持集群方式和广播方式的消费，它提供实时消息订阅机制，可以满足大多数用户的需求。
>
> 
>
> - **NameServer**：NameServer是一个非常简单的Topic路由注册中心，其角色类似Dubbo中的zookeeper，支持Broker的动态注册与发现。主要包括两个功能：Broker管理，NameServer接受Broker集群的注册信息并且保存下来作为路由信息的基本数据。然后提供心跳检测机制，检查Broker是否还存活；路由信息管理，每个NameServer将保存关于Broker集群的整个路由信息和用于客户端查询的队列信息。然后Producer和Conumser通过NameServer就可以知道整个Broker集群的路由信息，从而进行消息的投递和消费。NameServer通常也是集群的方式部署，各实例间相互不进行信息通讯。Broker是向每一台NameServer注册自己的路由信息，所以每一个NameServer实例上面都保存一份完整的路由信息。当某个NameServer因某种原因下线了，Broker仍然可以向其它NameServer同步其路由信息，Producer,Consumer仍然可以动态感知Broker的路由的信息。
>
> 
>
> - **BrokerServer**：Broker主要负责消息的存储、投递和查询以及服务高可用保证，为了实现这些功能，Broker包含了以下几个重要子模块。
>
> 1. Remoting Module：整个Broker的实体，负责处理来自clients端的请求。
> 2. Client Manager：负责管理客户端(Producer/Consumer)和维护Consumer的Topic订阅信息
> 3. Store Service：提供方便简单的API接口处理消息存储到物理硬盘和查询功能。
> 4. HA Service：高可用服务，提供Master Broker 和 Slave Broker之间的数据同步功能。
> 5. Index Service：根据特定的Message key对投递到Broker的消息进行索引服务，以提供消息的快速查询。



### 3.如何保证消息不被重复消费？

RocketMQ在什么情况下会出现重复消息？

> 1. 消息发送的时候，broket端已经完成持久化，此时网络中断，导致服务端对客户端响应失败，生产端发送失败并尝试重发；
> 2. 消息消费的时候，消费端在消费完成后，向broker更新偏移量的时候，此时网络中断，导致响应失败，投递消息可能就会重新投递；
> 3. 负载均衡消息重复（网络抖动、broker端重启、消费者重启）

冪等方案

> 1. 基于数据库唯一主键来保证重复数据不会重复插入；
> 2. 消费成功之后记录消息id，消费的时候先去查消息id是否存在；



### 4. 如何保证消息的可靠性传输？

**Rabbit：**

> 生产者：提交消息的时候，生产者和broker端提交消息的时候可能存在网络中断，导致提交消息失败。
>
> ​	同步：事物机制	
>
> ​	异步：confim回调机制
>
> broker端：消息存储问题
>
> ​	开启持久化
>
> 消费者：消费的时候，消费者突然宕机，该消息已经被自动确认，所以可能会丢失
>
> ​	关闭自动ack

**Kafka：**

> 生产者：
>
> ​	关闭自动提交offest
>
> broker端：topic中的partition leader同步到follower的时候，leader突然挂了，导致数据没有同步到follower，此时重新选举该follower为leader，此时数据就丢失了。
>
> 	1. 给 topic 设置 `replication.factor` 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
>  	2. 在 Kafka 服务端设置 `min.insync.replicas` 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
>  	3. 在 producer 端设置 `acks=all`：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了**。
>  	4. 在 producer 端设置 `retries=MAX`（很大很大很大的一个值，无限次重试的意思）：这个是**要求一旦写入失败，就无限重试**，卡在这里了。
>
> 消费者：
>
> ​	关闭自动ack

RocketMQ：

> 生产者：
>
> ​	同步发送消息
>
> ​	发送消息超时自动重试
>
> broker：
>
> ​	同步刷盘
>
> ​	queue主从模式
>
> 消费者：
>
> ​	消费ack机制
>
> ​	消费重试机制

### 5.如何保证消息的顺序性？

- 一个 topic，一个 partition，一个 consumer，内部单线程消费，单线程吞吐量太低，一般不会用这个。
- 写 N 个内存 queue，具有相同 key 的数据都到同一个内存 queue；然后对于 N 个线程，每个线程分别消费一个内存 queue 即可，这样就能保证顺序性。

### 6.如何解决消息队列延时以及过期失效问题？消息队列满后怎么办？有几百万消息堆积几个小时，说说怎么解决？

- 先停掉原先的consumer；
- 新建topic，partition/queue扩充原先的10倍；
- 然后调整consumer逻辑，将消息直接转发到新的topic中；
- 新的topic的消费者扩大到partition/queue数量；

如果遇到消息过期失效了，只能通过数据重导消息；

如果消息队列硬盘满了，只能直接丢弃消息；

### 7.如果让你写一个消息队列，如何进行架构设计？

- 可伸缩性，分布式架构
- 高可用性
- 消息可靠性
- 消息顺序性
- 如何数据不重复、数据不丢
- broker消息持久化